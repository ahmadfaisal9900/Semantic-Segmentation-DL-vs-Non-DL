{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.0,
  "eval_steps": 500,
  "global_step": 2250,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04,
      "grad_norm": 5.092167377471924,
      "learning_rate": 4.9800000000000004e-05,
      "loss": 3.5763,
      "step": 10
    },
    {
      "epoch": 0.08,
      "grad_norm": 5.228883743286133,
      "learning_rate": 4.96e-05,
      "loss": 3.364,
      "step": 20
    },
    {
      "epoch": 0.12,
      "grad_norm": 4.869215965270996,
      "learning_rate": 4.94e-05,
      "loss": 3.1811,
      "step": 30
    },
    {
      "epoch": 0.16,
      "grad_norm": 5.24432373046875,
      "learning_rate": 4.92e-05,
      "loss": 3.0176,
      "step": 40
    },
    {
      "epoch": 0.2,
      "grad_norm": 5.422859191894531,
      "learning_rate": 4.9e-05,
      "loss": 2.8474,
      "step": 50
    },
    {
      "epoch": 0.24,
      "grad_norm": 5.228950023651123,
      "learning_rate": 4.88e-05,
      "loss": 2.6705,
      "step": 60
    },
    {
      "epoch": 0.28,
      "grad_norm": 5.632293701171875,
      "learning_rate": 4.86e-05,
      "loss": 2.6384,
      "step": 70
    },
    {
      "epoch": 0.32,
      "grad_norm": 4.7369794845581055,
      "learning_rate": 4.8400000000000004e-05,
      "loss": 2.4857,
      "step": 80
    },
    {
      "epoch": 0.36,
      "grad_norm": 4.805081367492676,
      "learning_rate": 4.82e-05,
      "loss": 2.3393,
      "step": 90
    },
    {
      "epoch": 0.4,
      "grad_norm": 4.49395227432251,
      "learning_rate": 4.8e-05,
      "loss": 2.2156,
      "step": 100
    },
    {
      "epoch": 0.44,
      "grad_norm": 4.102570056915283,
      "learning_rate": 4.78e-05,
      "loss": 2.1419,
      "step": 110
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.482658386230469,
      "learning_rate": 4.76e-05,
      "loss": 2.0314,
      "step": 120
    },
    {
      "epoch": 0.52,
      "grad_norm": 4.338491916656494,
      "learning_rate": 4.74e-05,
      "loss": 1.9376,
      "step": 130
    },
    {
      "epoch": 0.56,
      "grad_norm": 4.811872959136963,
      "learning_rate": 4.72e-05,
      "loss": 1.9403,
      "step": 140
    },
    {
      "epoch": 0.6,
      "grad_norm": 6.331732749938965,
      "learning_rate": 4.7e-05,
      "loss": 1.8274,
      "step": 150
    },
    {
      "epoch": 0.64,
      "grad_norm": 4.3447065353393555,
      "learning_rate": 4.6800000000000006e-05,
      "loss": 1.7506,
      "step": 160
    },
    {
      "epoch": 0.68,
      "grad_norm": 4.243892669677734,
      "learning_rate": 4.660000000000001e-05,
      "loss": 1.6815,
      "step": 170
    },
    {
      "epoch": 0.72,
      "grad_norm": 4.195471286773682,
      "learning_rate": 4.64e-05,
      "loss": 1.6359,
      "step": 180
    },
    {
      "epoch": 0.76,
      "grad_norm": 5.256449222564697,
      "learning_rate": 4.6200000000000005e-05,
      "loss": 1.6799,
      "step": 190
    },
    {
      "epoch": 0.8,
      "grad_norm": 3.340242624282837,
      "learning_rate": 4.600000000000001e-05,
      "loss": 1.5181,
      "step": 200
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.3845202922821045,
      "learning_rate": 4.58e-05,
      "loss": 1.485,
      "step": 210
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.6652021408081055,
      "learning_rate": 4.5600000000000004e-05,
      "loss": 1.4638,
      "step": 220
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.612602949142456,
      "learning_rate": 4.5400000000000006e-05,
      "loss": 1.4315,
      "step": 230
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.041074514389038,
      "learning_rate": 4.52e-05,
      "loss": 1.3907,
      "step": 240
    },
    {
      "epoch": 1.0,
      "grad_norm": 3.8483028411865234,
      "learning_rate": 4.5e-05,
      "loss": 1.3101,
      "step": 250
    },
    {
      "epoch": 1.0,
      "eval_loss": NaN,
      "eval_runtime": 526.3178,
      "eval_samples_per_second": 2.004,
      "eval_steps_per_second": 0.502,
      "step": 250
    },
    {
      "epoch": 1.04,
      "grad_norm": 4.595865726470947,
      "learning_rate": 4.4800000000000005e-05,
      "loss": 1.2993,
      "step": 260
    },
    {
      "epoch": 1.08,
      "grad_norm": 5.026262283325195,
      "learning_rate": 4.46e-05,
      "loss": 1.2184,
      "step": 270
    },
    {
      "epoch": 1.12,
      "grad_norm": 2.541667938232422,
      "learning_rate": 4.44e-05,
      "loss": 1.2282,
      "step": 280
    },
    {
      "epoch": 1.16,
      "grad_norm": 3.216752290725708,
      "learning_rate": 4.4200000000000004e-05,
      "loss": 1.1833,
      "step": 290
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.279338836669922,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 1.1406,
      "step": 300
    },
    {
      "epoch": 1.24,
      "grad_norm": 2.596991539001465,
      "learning_rate": 4.38e-05,
      "loss": 1.0754,
      "step": 310
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.9222571849823,
      "learning_rate": 4.36e-05,
      "loss": 1.0328,
      "step": 320
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.9753828048706055,
      "learning_rate": 4.3400000000000005e-05,
      "loss": 1.0798,
      "step": 330
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 3.120143175125122,
      "learning_rate": 4.32e-05,
      "loss": 1.0317,
      "step": 340
    },
    {
      "epoch": 1.4,
      "grad_norm": 3.0121564865112305,
      "learning_rate": 4.3e-05,
      "loss": 0.9568,
      "step": 350
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.7354633808135986,
      "learning_rate": 4.2800000000000004e-05,
      "loss": 1.0152,
      "step": 360
    },
    {
      "epoch": 1.48,
      "grad_norm": 2.113018274307251,
      "learning_rate": 4.26e-05,
      "loss": 0.978,
      "step": 370
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.7595019340515137,
      "learning_rate": 4.24e-05,
      "loss": 0.9385,
      "step": 380
    },
    {
      "epoch": 1.56,
      "grad_norm": 2.1930696964263916,
      "learning_rate": 4.22e-05,
      "loss": 0.9137,
      "step": 390
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.67856502532959,
      "learning_rate": 4.2e-05,
      "loss": 0.8801,
      "step": 400
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 2.3464713096618652,
      "learning_rate": 4.18e-05,
      "loss": 0.8857,
      "step": 410
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 1.7850220203399658,
      "learning_rate": 4.16e-05,
      "loss": 0.8588,
      "step": 420
    },
    {
      "epoch": 1.72,
      "grad_norm": 1.979945182800293,
      "learning_rate": 4.14e-05,
      "loss": 0.8074,
      "step": 430
    },
    {
      "epoch": 1.76,
      "grad_norm": 2.235196113586426,
      "learning_rate": 4.12e-05,
      "loss": 0.8136,
      "step": 440
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.2840521335601807,
      "learning_rate": 4.1e-05,
      "loss": 0.8069,
      "step": 450
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 3.4110841751098633,
      "learning_rate": 4.08e-05,
      "loss": 0.8314,
      "step": 460
    },
    {
      "epoch": 1.88,
      "grad_norm": 2.6548633575439453,
      "learning_rate": 4.0600000000000004e-05,
      "loss": 0.7632,
      "step": 470
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.8712069988250732,
      "learning_rate": 4.0400000000000006e-05,
      "loss": 0.7497,
      "step": 480
    },
    {
      "epoch": 1.96,
      "grad_norm": 1.3389064073562622,
      "learning_rate": 4.02e-05,
      "loss": 0.74,
      "step": 490
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.8284846544265747,
      "learning_rate": 4e-05,
      "loss": 0.7623,
      "step": 500
    },
    {
      "epoch": 2.0,
      "eval_loss": NaN,
      "eval_runtime": 490.2942,
      "eval_samples_per_second": 2.152,
      "eval_steps_per_second": 0.538,
      "step": 500
    },
    {
      "epoch": 2.04,
      "grad_norm": 1.6114835739135742,
      "learning_rate": 3.9800000000000005e-05,
      "loss": 0.7393,
      "step": 510
    },
    {
      "epoch": 2.08,
      "grad_norm": 1.5018821954727173,
      "learning_rate": 3.960000000000001e-05,
      "loss": 0.7567,
      "step": 520
    },
    {
      "epoch": 2.12,
      "grad_norm": 1.726158857345581,
      "learning_rate": 3.94e-05,
      "loss": 0.7147,
      "step": 530
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.9442792534828186,
      "learning_rate": 3.9200000000000004e-05,
      "loss": 0.7149,
      "step": 540
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.4155217409133911,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.7033,
      "step": 550
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.5618648529052734,
      "learning_rate": 3.88e-05,
      "loss": 0.6967,
      "step": 560
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 3.9455618858337402,
      "learning_rate": 3.86e-05,
      "loss": 0.7057,
      "step": 570
    },
    {
      "epoch": 2.32,
      "grad_norm": 1.3148404359817505,
      "learning_rate": 3.8400000000000005e-05,
      "loss": 0.6976,
      "step": 580
    },
    {
      "epoch": 2.36,
      "grad_norm": 1.7631330490112305,
      "learning_rate": 3.82e-05,
      "loss": 0.6863,
      "step": 590
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.9850684404373169,
      "learning_rate": 3.8e-05,
      "loss": 0.6494,
      "step": 600
    },
    {
      "epoch": 2.44,
      "grad_norm": 2.1056630611419678,
      "learning_rate": 3.7800000000000004e-05,
      "loss": 0.6995,
      "step": 610
    },
    {
      "epoch": 2.48,
      "grad_norm": 1.3866362571716309,
      "learning_rate": 3.76e-05,
      "loss": 0.6498,
      "step": 620
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.516049385070801,
      "learning_rate": 3.74e-05,
      "loss": 0.6981,
      "step": 630
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.1852619647979736,
      "learning_rate": 3.72e-05,
      "loss": 0.6875,
      "step": 640
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.5996770858764648,
      "learning_rate": 3.7e-05,
      "loss": 0.6392,
      "step": 650
    },
    {
      "epoch": 2.64,
      "grad_norm": 1.483452320098877,
      "learning_rate": 3.68e-05,
      "loss": 0.6715,
      "step": 660
    },
    {
      "epoch": 2.68,
      "grad_norm": 1.2543741464614868,
      "learning_rate": 3.66e-05,
      "loss": 0.6373,
      "step": 670
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 1.5209157466888428,
      "learning_rate": 3.6400000000000004e-05,
      "loss": 0.6642,
      "step": 680
    },
    {
      "epoch": 2.76,
      "grad_norm": 1.1497944593429565,
      "learning_rate": 3.62e-05,
      "loss": 0.6395,
      "step": 690
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.9345824718475342,
      "learning_rate": 3.6e-05,
      "loss": 0.6264,
      "step": 700
    },
    {
      "epoch": 2.84,
      "grad_norm": 1.7276995182037354,
      "learning_rate": 3.58e-05,
      "loss": 0.669,
      "step": 710
    },
    {
      "epoch": 2.88,
      "grad_norm": 1.662819266319275,
      "learning_rate": 3.56e-05,
      "loss": 0.6393,
      "step": 720
    },
    {
      "epoch": 2.92,
      "grad_norm": 1.8369418382644653,
      "learning_rate": 3.54e-05,
      "loss": 0.6204,
      "step": 730
    },
    {
      "epoch": 2.96,
      "grad_norm": 1.0007959604263306,
      "learning_rate": 3.52e-05,
      "loss": 0.6399,
      "step": 740
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.095266580581665,
      "learning_rate": 3.5e-05,
      "loss": 0.6809,
      "step": 750
    },
    {
      "epoch": 3.0,
      "eval_loss": NaN,
      "eval_runtime": 496.307,
      "eval_samples_per_second": 2.126,
      "eval_steps_per_second": 0.532,
      "step": 750
    },
    {
      "epoch": 3.04,
      "grad_norm": 1.2733590602874756,
      "learning_rate": 3.48e-05,
      "loss": 0.6187,
      "step": 760
    },
    {
      "epoch": 3.08,
      "grad_norm": 2.0215280055999756,
      "learning_rate": 3.46e-05,
      "loss": 0.6401,
      "step": 770
    },
    {
      "epoch": 3.12,
      "grad_norm": 1.646161675453186,
      "learning_rate": 3.4399999999999996e-05,
      "loss": 0.6318,
      "step": 780
    },
    {
      "epoch": 3.16,
      "grad_norm": 2.414684534072876,
      "learning_rate": 3.4200000000000005e-05,
      "loss": 0.6158,
      "step": 790
    },
    {
      "epoch": 3.2,
      "grad_norm": 1.7235784530639648,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.6093,
      "step": 800
    },
    {
      "epoch": 3.24,
      "grad_norm": 2.371091842651367,
      "learning_rate": 3.38e-05,
      "loss": 0.584,
      "step": 810
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 3.5354788303375244,
      "learning_rate": 3.3600000000000004e-05,
      "loss": 0.6629,
      "step": 820
    },
    {
      "epoch": 3.32,
      "grad_norm": 1.9008057117462158,
      "learning_rate": 3.3400000000000005e-05,
      "loss": 0.6048,
      "step": 830
    },
    {
      "epoch": 3.36,
      "grad_norm": 1.632330298423767,
      "learning_rate": 3.32e-05,
      "loss": 0.5828,
      "step": 840
    },
    {
      "epoch": 3.4,
      "grad_norm": 2.0112085342407227,
      "learning_rate": 3.3e-05,
      "loss": 0.6164,
      "step": 850
    },
    {
      "epoch": 3.44,
      "grad_norm": 1.7648406028747559,
      "learning_rate": 3.2800000000000004e-05,
      "loss": 0.5538,
      "step": 860
    },
    {
      "epoch": 3.48,
      "grad_norm": 2.5218684673309326,
      "learning_rate": 3.26e-05,
      "loss": 0.599,
      "step": 870
    },
    {
      "epoch": 3.52,
      "grad_norm": 2.079986810684204,
      "learning_rate": 3.24e-05,
      "loss": 0.5826,
      "step": 880
    },
    {
      "epoch": 3.56,
      "grad_norm": 3.5884578227996826,
      "learning_rate": 3.2200000000000003e-05,
      "loss": 0.5686,
      "step": 890
    },
    {
      "epoch": 3.6,
      "grad_norm": 2.091489315032959,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.6315,
      "step": 900
    },
    {
      "epoch": 3.64,
      "grad_norm": 1.7558079957962036,
      "learning_rate": 3.18e-05,
      "loss": 0.5827,
      "step": 910
    },
    {
      "epoch": 3.68,
      "grad_norm": 1.3570696115493774,
      "learning_rate": 3.16e-05,
      "loss": 0.6019,
      "step": 920
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 2.697603702545166,
      "learning_rate": 3.1400000000000004e-05,
      "loss": 0.5865,
      "step": 930
    },
    {
      "epoch": 3.76,
      "grad_norm": 2.186041831970215,
      "learning_rate": 3.12e-05,
      "loss": 0.595,
      "step": 940
    },
    {
      "epoch": 3.8,
      "grad_norm": 1.8933768272399902,
      "learning_rate": 3.1e-05,
      "loss": 0.5824,
      "step": 950
    },
    {
      "epoch": 3.84,
      "grad_norm": 1.7720588445663452,
      "learning_rate": 3.08e-05,
      "loss": 0.5795,
      "step": 960
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.942990243434906,
      "learning_rate": 3.06e-05,
      "loss": 0.6113,
      "step": 970
    },
    {
      "epoch": 3.92,
      "grad_norm": 1.1978086233139038,
      "learning_rate": 3.04e-05,
      "loss": 0.5986,
      "step": 980
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.9901425242424011,
      "learning_rate": 3.02e-05,
      "loss": 0.6177,
      "step": 990
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.2549538612365723,
      "learning_rate": 3e-05,
      "loss": 0.6271,
      "step": 1000
    },
    {
      "epoch": 4.0,
      "eval_loss": NaN,
      "eval_runtime": 496.4993,
      "eval_samples_per_second": 2.125,
      "eval_steps_per_second": 0.532,
      "step": 1000
    },
    {
      "epoch": 4.04,
      "grad_norm": 1.0573891401290894,
      "learning_rate": 2.98e-05,
      "loss": 0.578,
      "step": 1010
    },
    {
      "epoch": 4.08,
      "grad_norm": 2.120399236679077,
      "learning_rate": 2.96e-05,
      "loss": 0.5929,
      "step": 1020
    },
    {
      "epoch": 4.12,
      "grad_norm": 1.4516524076461792,
      "learning_rate": 2.94e-05,
      "loss": 0.567,
      "step": 1030
    },
    {
      "epoch": 4.16,
      "grad_norm": 1.9848273992538452,
      "learning_rate": 2.9199999999999998e-05,
      "loss": 0.6213,
      "step": 1040
    },
    {
      "epoch": 4.2,
      "grad_norm": 2.39884352684021,
      "learning_rate": 2.9e-05,
      "loss": 0.6145,
      "step": 1050
    },
    {
      "epoch": 4.24,
      "grad_norm": 1.6131925582885742,
      "learning_rate": 2.88e-05,
      "loss": 0.5629,
      "step": 1060
    },
    {
      "epoch": 4.28,
      "grad_norm": 0.8967933058738708,
      "learning_rate": 2.86e-05,
      "loss": 0.574,
      "step": 1070
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.9750183820724487,
      "learning_rate": 2.84e-05,
      "loss": 0.5915,
      "step": 1080
    },
    {
      "epoch": 4.36,
      "grad_norm": 1.3246806859970093,
      "learning_rate": 2.8199999999999998e-05,
      "loss": 0.5344,
      "step": 1090
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.8560121655464172,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.5491,
      "step": 1100
    },
    {
      "epoch": 4.44,
      "grad_norm": 1.3376476764678955,
      "learning_rate": 2.7800000000000005e-05,
      "loss": 0.5683,
      "step": 1110
    },
    {
      "epoch": 4.48,
      "grad_norm": 2.6646499633789062,
      "learning_rate": 2.7600000000000003e-05,
      "loss": 0.5868,
      "step": 1120
    },
    {
      "epoch": 4.52,
      "grad_norm": 1.33975088596344,
      "learning_rate": 2.7400000000000002e-05,
      "loss": 0.595,
      "step": 1130
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 1.39490807056427,
      "learning_rate": 2.7200000000000004e-05,
      "loss": 0.602,
      "step": 1140
    },
    {
      "epoch": 4.6,
      "grad_norm": 2.8481242656707764,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.5767,
      "step": 1150
    },
    {
      "epoch": 4.64,
      "grad_norm": 1.3646169900894165,
      "learning_rate": 2.6800000000000004e-05,
      "loss": 0.5663,
      "step": 1160
    },
    {
      "epoch": 4.68,
      "grad_norm": 1.1573301553726196,
      "learning_rate": 2.6600000000000003e-05,
      "loss": 0.6109,
      "step": 1170
    },
    {
      "epoch": 4.72,
      "grad_norm": 2.619225025177002,
      "learning_rate": 2.64e-05,
      "loss": 0.5578,
      "step": 1180
    },
    {
      "epoch": 4.76,
      "grad_norm": 1.50508713722229,
      "learning_rate": 2.6200000000000003e-05,
      "loss": 0.5227,
      "step": 1190
    },
    {
      "epoch": 4.8,
      "grad_norm": 2.7642006874084473,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.5482,
      "step": 1200
    },
    {
      "epoch": 4.84,
      "grad_norm": 5.167485237121582,
      "learning_rate": 2.58e-05,
      "loss": 0.5771,
      "step": 1210
    },
    {
      "epoch": 4.88,
      "grad_norm": 1.4884015321731567,
      "learning_rate": 2.5600000000000002e-05,
      "loss": 0.5236,
      "step": 1220
    },
    {
      "epoch": 4.92,
      "grad_norm": 1.9033033847808838,
      "learning_rate": 2.54e-05,
      "loss": 0.5631,
      "step": 1230
    },
    {
      "epoch": 4.96,
      "grad_norm": 3.1938164234161377,
      "learning_rate": 2.5200000000000003e-05,
      "loss": 0.5283,
      "step": 1240
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.773199439048767,
      "learning_rate": 2.5e-05,
      "loss": 0.5621,
      "step": 1250
    },
    {
      "epoch": 5.0,
      "eval_loss": NaN,
      "eval_runtime": 495.5196,
      "eval_samples_per_second": 2.129,
      "eval_steps_per_second": 0.533,
      "step": 1250
    },
    {
      "epoch": 5.04,
      "grad_norm": 2.048679828643799,
      "learning_rate": 2.48e-05,
      "loss": 0.5713,
      "step": 1260
    },
    {
      "epoch": 5.08,
      "grad_norm": 1.1277320384979248,
      "learning_rate": 2.46e-05,
      "loss": 0.5649,
      "step": 1270
    },
    {
      "epoch": 5.12,
      "grad_norm": 3.717146635055542,
      "learning_rate": 2.442e-05,
      "loss": 0.5758,
      "step": 1280
    },
    {
      "epoch": 5.16,
      "grad_norm": 1.1960700750350952,
      "learning_rate": 2.4220000000000002e-05,
      "loss": 0.5369,
      "step": 1290
    },
    {
      "epoch": 5.2,
      "grad_norm": 1.8941689729690552,
      "learning_rate": 2.402e-05,
      "loss": 0.5325,
      "step": 1300
    },
    {
      "epoch": 5.24,
      "grad_norm": 2.5099878311157227,
      "learning_rate": 2.3820000000000002e-05,
      "loss": 0.53,
      "step": 1310
    },
    {
      "epoch": 5.28,
      "grad_norm": 1.335951328277588,
      "learning_rate": 2.362e-05,
      "loss": 0.5653,
      "step": 1320
    },
    {
      "epoch": 5.32,
      "grad_norm": 1.4350221157073975,
      "learning_rate": 2.342e-05,
      "loss": 0.5167,
      "step": 1330
    },
    {
      "epoch": 5.36,
      "grad_norm": 2.4280447959899902,
      "learning_rate": 2.322e-05,
      "loss": 0.6062,
      "step": 1340
    },
    {
      "epoch": 5.4,
      "grad_norm": 2.442166566848755,
      "learning_rate": 2.302e-05,
      "loss": 0.541,
      "step": 1350
    },
    {
      "epoch": 5.44,
      "grad_norm": 1.3949103355407715,
      "learning_rate": 2.282e-05,
      "loss": 0.645,
      "step": 1360
    },
    {
      "epoch": 5.48,
      "grad_norm": 1.6755516529083252,
      "learning_rate": 2.2620000000000004e-05,
      "loss": 0.5642,
      "step": 1370
    },
    {
      "epoch": 5.52,
      "grad_norm": 1.3164746761322021,
      "learning_rate": 2.2420000000000002e-05,
      "loss": 0.5426,
      "step": 1380
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 1.4392421245574951,
      "learning_rate": 2.222e-05,
      "loss": 0.5631,
      "step": 1390
    },
    {
      "epoch": 5.6,
      "grad_norm": 1.0674400329589844,
      "learning_rate": 2.2020000000000003e-05,
      "loss": 0.5101,
      "step": 1400
    },
    {
      "epoch": 5.64,
      "grad_norm": 3.730813503265381,
      "learning_rate": 2.182e-05,
      "loss": 0.5548,
      "step": 1410
    },
    {
      "epoch": 5.68,
      "grad_norm": 1.2482538223266602,
      "learning_rate": 2.162e-05,
      "loss": 0.4866,
      "step": 1420
    },
    {
      "epoch": 5.72,
      "grad_norm": 1.7138583660125732,
      "learning_rate": 2.142e-05,
      "loss": 0.5793,
      "step": 1430
    },
    {
      "epoch": 5.76,
      "grad_norm": 5.516347408294678,
      "learning_rate": 2.122e-05,
      "loss": 0.566,
      "step": 1440
    },
    {
      "epoch": 5.8,
      "grad_norm": 1.6937092542648315,
      "learning_rate": 2.1020000000000002e-05,
      "loss": 0.5348,
      "step": 1450
    },
    {
      "epoch": 5.84,
      "grad_norm": 1.9148287773132324,
      "learning_rate": 2.082e-05,
      "loss": 0.5128,
      "step": 1460
    },
    {
      "epoch": 5.88,
      "grad_norm": 1.288262963294983,
      "learning_rate": 2.062e-05,
      "loss": 0.504,
      "step": 1470
    },
    {
      "epoch": 5.92,
      "grad_norm": 1.685740351676941,
      "learning_rate": 2.042e-05,
      "loss": 0.5819,
      "step": 1480
    },
    {
      "epoch": 5.96,
      "grad_norm": 1.9759997129440308,
      "learning_rate": 2.022e-05,
      "loss": 0.5804,
      "step": 1490
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.1126365661621094,
      "learning_rate": 2.002e-05,
      "loss": 0.5154,
      "step": 1500
    },
    {
      "epoch": 6.0,
      "eval_loss": NaN,
      "eval_runtime": 486.2906,
      "eval_samples_per_second": 2.169,
      "eval_steps_per_second": 0.543,
      "step": 1500
    },
    {
      "epoch": 6.04,
      "grad_norm": 1.3360627889633179,
      "learning_rate": 1.982e-05,
      "loss": 0.5766,
      "step": 1510
    },
    {
      "epoch": 6.08,
      "grad_norm": 1.2892462015151978,
      "learning_rate": 1.9620000000000002e-05,
      "loss": 0.5156,
      "step": 1520
    },
    {
      "epoch": 6.12,
      "grad_norm": 2.4718515872955322,
      "learning_rate": 1.942e-05,
      "loss": 0.5068,
      "step": 1530
    },
    {
      "epoch": 6.16,
      "grad_norm": 2.5013177394866943,
      "learning_rate": 1.9220000000000002e-05,
      "loss": 0.5574,
      "step": 1540
    },
    {
      "epoch": 6.2,
      "grad_norm": 1.6518017053604126,
      "learning_rate": 1.902e-05,
      "loss": 0.5826,
      "step": 1550
    },
    {
      "epoch": 6.24,
      "grad_norm": 2.39076828956604,
      "learning_rate": 1.8820000000000003e-05,
      "loss": 0.502,
      "step": 1560
    },
    {
      "epoch": 6.28,
      "grad_norm": 2.8022336959838867,
      "learning_rate": 1.862e-05,
      "loss": 0.5609,
      "step": 1570
    },
    {
      "epoch": 6.32,
      "grad_norm": 1.8218053579330444,
      "learning_rate": 1.842e-05,
      "loss": 0.5276,
      "step": 1580
    },
    {
      "epoch": 6.36,
      "grad_norm": 1.7394154071807861,
      "learning_rate": 1.8220000000000002e-05,
      "loss": 0.541,
      "step": 1590
    },
    {
      "epoch": 6.4,
      "grad_norm": 2.095468759536743,
      "learning_rate": 1.802e-05,
      "loss": 0.5407,
      "step": 1600
    },
    {
      "epoch": 6.44,
      "grad_norm": 2.038707971572876,
      "learning_rate": 1.7820000000000002e-05,
      "loss": 0.5667,
      "step": 1610
    },
    {
      "epoch": 6.48,
      "grad_norm": 3.10844087600708,
      "learning_rate": 1.762e-05,
      "loss": 0.4995,
      "step": 1620
    },
    {
      "epoch": 6.52,
      "grad_norm": 1.2713167667388916,
      "learning_rate": 1.742e-05,
      "loss": 0.5302,
      "step": 1630
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 5.998948097229004,
      "learning_rate": 1.722e-05,
      "loss": 0.5672,
      "step": 1640
    },
    {
      "epoch": 6.6,
      "grad_norm": 2.4958059787750244,
      "learning_rate": 1.702e-05,
      "loss": 0.5476,
      "step": 1650
    },
    {
      "epoch": 6.64,
      "grad_norm": 2.524463653564453,
      "learning_rate": 1.6819999999999998e-05,
      "loss": 0.5514,
      "step": 1660
    },
    {
      "epoch": 6.68,
      "grad_norm": 2.5183677673339844,
      "learning_rate": 1.662e-05,
      "loss": 0.5124,
      "step": 1670
    },
    {
      "epoch": 6.72,
      "grad_norm": 1.7098859548568726,
      "learning_rate": 1.6420000000000002e-05,
      "loss": 0.5027,
      "step": 1680
    },
    {
      "epoch": 6.76,
      "grad_norm": 1.6883227825164795,
      "learning_rate": 1.622e-05,
      "loss": 0.5662,
      "step": 1690
    },
    {
      "epoch": 6.8,
      "grad_norm": 2.91938853263855,
      "learning_rate": 1.6020000000000002e-05,
      "loss": 0.4998,
      "step": 1700
    },
    {
      "epoch": 6.84,
      "grad_norm": 1.0590825080871582,
      "learning_rate": 1.582e-05,
      "loss": 0.5147,
      "step": 1710
    },
    {
      "epoch": 6.88,
      "grad_norm": 1.628420114517212,
      "learning_rate": 1.5620000000000003e-05,
      "loss": 0.5097,
      "step": 1720
    },
    {
      "epoch": 6.92,
      "grad_norm": 1.7817294597625732,
      "learning_rate": 1.542e-05,
      "loss": 0.5315,
      "step": 1730
    },
    {
      "epoch": 6.96,
      "grad_norm": 1.6600589752197266,
      "learning_rate": 1.5220000000000002e-05,
      "loss": 0.5718,
      "step": 1740
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.4226293563842773,
      "learning_rate": 1.502e-05,
      "loss": 0.5462,
      "step": 1750
    },
    {
      "epoch": 7.0,
      "eval_loss": NaN,
      "eval_runtime": 484.6131,
      "eval_samples_per_second": 2.177,
      "eval_steps_per_second": 0.545,
      "step": 1750
    },
    {
      "epoch": 7.04,
      "grad_norm": 3.853203773498535,
      "learning_rate": 1.482e-05,
      "loss": 0.5477,
      "step": 1760
    },
    {
      "epoch": 7.08,
      "grad_norm": 2.8441436290740967,
      "learning_rate": 1.462e-05,
      "loss": 0.5692,
      "step": 1770
    },
    {
      "epoch": 7.12,
      "grad_norm": 2.356008529663086,
      "learning_rate": 1.4420000000000001e-05,
      "loss": 0.5254,
      "step": 1780
    },
    {
      "epoch": 7.16,
      "grad_norm": 2.184917688369751,
      "learning_rate": 1.422e-05,
      "loss": 0.4969,
      "step": 1790
    },
    {
      "epoch": 7.2,
      "grad_norm": 5.931649208068848,
      "learning_rate": 1.402e-05,
      "loss": 0.5338,
      "step": 1800
    },
    {
      "epoch": 7.24,
      "grad_norm": 1.1853646039962769,
      "learning_rate": 1.382e-05,
      "loss": 0.5811,
      "step": 1810
    },
    {
      "epoch": 7.28,
      "grad_norm": 1.7797471284866333,
      "learning_rate": 1.362e-05,
      "loss": 0.4794,
      "step": 1820
    },
    {
      "epoch": 7.32,
      "grad_norm": 1.8446308374404907,
      "learning_rate": 1.3420000000000002e-05,
      "loss": 0.5347,
      "step": 1830
    },
    {
      "epoch": 7.36,
      "grad_norm": 1.249861240386963,
      "learning_rate": 1.3220000000000002e-05,
      "loss": 0.5336,
      "step": 1840
    },
    {
      "epoch": 7.4,
      "grad_norm": 2.4159955978393555,
      "learning_rate": 1.3020000000000002e-05,
      "loss": 0.498,
      "step": 1850
    },
    {
      "epoch": 7.44,
      "grad_norm": 2.6428489685058594,
      "learning_rate": 1.2820000000000001e-05,
      "loss": 0.5223,
      "step": 1860
    },
    {
      "epoch": 7.48,
      "grad_norm": 2.9251787662506104,
      "learning_rate": 1.2620000000000001e-05,
      "loss": 0.4969,
      "step": 1870
    },
    {
      "epoch": 7.52,
      "grad_norm": 1.8136297464370728,
      "learning_rate": 1.2420000000000001e-05,
      "loss": 0.5265,
      "step": 1880
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 1.9490591287612915,
      "learning_rate": 1.2220000000000002e-05,
      "loss": 0.4855,
      "step": 1890
    },
    {
      "epoch": 7.6,
      "grad_norm": 1.6640088558197021,
      "learning_rate": 1.202e-05,
      "loss": 0.5293,
      "step": 1900
    },
    {
      "epoch": 7.64,
      "grad_norm": 2.195345401763916,
      "learning_rate": 1.182e-05,
      "loss": 0.5182,
      "step": 1910
    },
    {
      "epoch": 7.68,
      "grad_norm": 1.7174031734466553,
      "learning_rate": 1.162e-05,
      "loss": 0.4917,
      "step": 1920
    },
    {
      "epoch": 7.72,
      "grad_norm": 2.547879934310913,
      "learning_rate": 1.142e-05,
      "loss": 0.5189,
      "step": 1930
    },
    {
      "epoch": 7.76,
      "grad_norm": 1.7288291454315186,
      "learning_rate": 1.122e-05,
      "loss": 0.5259,
      "step": 1940
    },
    {
      "epoch": 7.8,
      "grad_norm": 2.0800890922546387,
      "learning_rate": 1.1020000000000001e-05,
      "loss": 0.5064,
      "step": 1950
    },
    {
      "epoch": 7.84,
      "grad_norm": 1.6964914798736572,
      "learning_rate": 1.0820000000000001e-05,
      "loss": 0.5351,
      "step": 1960
    },
    {
      "epoch": 7.88,
      "grad_norm": 1.7306252717971802,
      "learning_rate": 1.062e-05,
      "loss": 0.5416,
      "step": 1970
    },
    {
      "epoch": 7.92,
      "grad_norm": 1.7686775922775269,
      "learning_rate": 1.042e-05,
      "loss": 0.5346,
      "step": 1980
    },
    {
      "epoch": 7.96,
      "grad_norm": 2.0956342220306396,
      "learning_rate": 1.022e-05,
      "loss": 0.5756,
      "step": 1990
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.4285553693771362,
      "learning_rate": 1.002e-05,
      "loss": 0.5003,
      "step": 2000
    },
    {
      "epoch": 8.0,
      "eval_loss": NaN,
      "eval_runtime": 494.3932,
      "eval_samples_per_second": 2.134,
      "eval_steps_per_second": 0.534,
      "step": 2000
    },
    {
      "epoch": 8.04,
      "grad_norm": 6.488912105560303,
      "learning_rate": 9.820000000000001e-06,
      "loss": 0.5187,
      "step": 2010
    },
    {
      "epoch": 8.08,
      "grad_norm": 2.3596956729888916,
      "learning_rate": 9.62e-06,
      "loss": 0.5335,
      "step": 2020
    },
    {
      "epoch": 8.12,
      "grad_norm": 1.3745447397232056,
      "learning_rate": 9.420000000000001e-06,
      "loss": 0.5129,
      "step": 2030
    },
    {
      "epoch": 8.16,
      "grad_norm": 1.5994919538497925,
      "learning_rate": 9.220000000000002e-06,
      "loss": 0.5182,
      "step": 2040
    },
    {
      "epoch": 8.2,
      "grad_norm": 1.9444172382354736,
      "learning_rate": 9.02e-06,
      "loss": 0.5127,
      "step": 2050
    },
    {
      "epoch": 8.24,
      "grad_norm": 1.9021531343460083,
      "learning_rate": 8.82e-06,
      "loss": 0.5483,
      "step": 2060
    },
    {
      "epoch": 8.28,
      "grad_norm": 2.51033091545105,
      "learning_rate": 8.62e-06,
      "loss": 0.5284,
      "step": 2070
    },
    {
      "epoch": 8.32,
      "grad_norm": 2.4672038555145264,
      "learning_rate": 8.42e-06,
      "loss": 0.5316,
      "step": 2080
    },
    {
      "epoch": 8.36,
      "grad_norm": 2.5974414348602295,
      "learning_rate": 8.22e-06,
      "loss": 0.5153,
      "step": 2090
    },
    {
      "epoch": 8.4,
      "grad_norm": 2.4718918800354004,
      "learning_rate": 8.02e-06,
      "loss": 0.5123,
      "step": 2100
    },
    {
      "epoch": 8.44,
      "grad_norm": 1.3596394062042236,
      "learning_rate": 7.820000000000001e-06,
      "loss": 0.4648,
      "step": 2110
    },
    {
      "epoch": 8.48,
      "grad_norm": 1.4108277559280396,
      "learning_rate": 7.620000000000001e-06,
      "loss": 0.5179,
      "step": 2120
    },
    {
      "epoch": 8.52,
      "grad_norm": 6.509341239929199,
      "learning_rate": 7.420000000000001e-06,
      "loss": 0.5197,
      "step": 2130
    },
    {
      "epoch": 8.56,
      "grad_norm": 1.594595193862915,
      "learning_rate": 7.22e-06,
      "loss": 0.5227,
      "step": 2140
    },
    {
      "epoch": 8.6,
      "grad_norm": 2.349315643310547,
      "learning_rate": 7.0200000000000006e-06,
      "loss": 0.5344,
      "step": 2150
    },
    {
      "epoch": 8.64,
      "grad_norm": 2.7011806964874268,
      "learning_rate": 6.82e-06,
      "loss": 0.5198,
      "step": 2160
    },
    {
      "epoch": 8.68,
      "grad_norm": 1.5278420448303223,
      "learning_rate": 6.62e-06,
      "loss": 0.4838,
      "step": 2170
    },
    {
      "epoch": 8.72,
      "grad_norm": 2.4711005687713623,
      "learning_rate": 6.4199999999999995e-06,
      "loss": 0.5327,
      "step": 2180
    },
    {
      "epoch": 8.76,
      "grad_norm": 1.8375515937805176,
      "learning_rate": 6.22e-06,
      "loss": 0.544,
      "step": 2190
    },
    {
      "epoch": 8.8,
      "grad_norm": 1.736785888671875,
      "learning_rate": 6.02e-06,
      "loss": 0.535,
      "step": 2200
    },
    {
      "epoch": 8.84,
      "grad_norm": 2.725550413131714,
      "learning_rate": 5.82e-06,
      "loss": 0.5098,
      "step": 2210
    },
    {
      "epoch": 8.88,
      "grad_norm": 1.2841788530349731,
      "learning_rate": 5.62e-06,
      "loss": 0.484,
      "step": 2220
    },
    {
      "epoch": 8.92,
      "grad_norm": 1.6331003904342651,
      "learning_rate": 5.42e-06,
      "loss": 0.5508,
      "step": 2230
    },
    {
      "epoch": 8.96,
      "grad_norm": 1.2860854864120483,
      "learning_rate": 5.220000000000001e-06,
      "loss": 0.5456,
      "step": 2240
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.698928713798523,
      "learning_rate": 5.02e-06,
      "loss": 0.4555,
      "step": 2250
    },
    {
      "epoch": 9.0,
      "eval_loss": NaN,
      "eval_runtime": 491.9793,
      "eval_samples_per_second": 2.144,
      "eval_steps_per_second": 0.537,
      "step": 2250
    }
  ],
  "logging_steps": 10,
  "max_steps": 2500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.58100850999296e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
